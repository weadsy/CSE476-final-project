{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393516c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Minimal setup\n",
    "# If needed (uncomment in a notebook):\n",
    "# !pip install requests python-dotenv\n",
    "\n",
    "import os, json, textwrap, re, time\n",
    "import requests\n",
    "\n",
    "API_KEY  = os.getenv(\"OPENAI_API_KEY\", \"cse476\")\n",
    "API_BASE = os.getenv(\"API_BASE\", \"http://10.4.58.53:41701/v1\")  \n",
    "MODEL    = os.getenv(\"MODEL_NAME\", \"bens_model\")              \n",
    "\n",
    "def call_model_chat_completions(prompt: str,\n",
    "                                system: str = \"You are a helpful assistant. Reply with only the final answer‚Äîno explanation.\",\n",
    "                                model: str = MODEL,\n",
    "                                temperature: float = 0.3,\n",
    "                                timeout: int = 60,\n",
    "                                max_tokens: int = 128) -> dict:\n",
    "    \"\"\"\n",
    "    Calls an OpenAI-style /v1/chat/completions endpoint and returns:\n",
    "    { 'ok': bool, 'text': str or None, 'raw': dict or None, 'status': int, 'error': str or None, 'headers': dict }\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE}/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\":  \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        #{'id': 'chatcmpl-88b6d7e18a5542b5bed5bf2828f0661e', 'object': 'chat.completion', 'created': 1763204718, 'model': 'bens_model', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'US Highway 281', 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'reasoning_content': None}, 'logprobs': None, 'finish_reason': 'stop', 'stop_reason': None, 'token_ids': None}], 'service_tier': None, 'system_fingerprint': None, 'usage': {'prompt_tokens': 50, 'total_tokens': 57, 'completion_tokens': 7, 'prompt_tokens_details': None}, 'prompt_logprobs': None, 'prompt_token_ids': None, 'kv_transfer_params': None}\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "        status = resp.status_code\n",
    "        hdrs   = dict(resp.headers)\n",
    "        if status == 200:\n",
    "            data = resp.json()\n",
    "            #print(data)\n",
    "            text = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            tokens_used = data.get(\"usage\",[{}]).get(\"completion_tokens\", {})\n",
    "            #print('used tokens:', tokens_used)\n",
    "            \n",
    "            return {\"ok\": True, \"text\": text, \"raw\": data, \"status\": status, \"error\": None, \"headers\": hdrs, \"tokens_used\":tokens_used}\n",
    "        else:\n",
    "            # try best-effort to surface error text\n",
    "            err_text = None\n",
    "            try:\n",
    "                err_text = resp.json()\n",
    "            except Exception:\n",
    "                err_text = resp.text\n",
    "            return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": status, \"error\": str(err_text), \"headers\": hdrs}\n",
    "    except requests.RequestException as e:\n",
    "        return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": -1, \"error\": str(e), \"headers\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f36f76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dc9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Direct call example\n",
    "def direct_call(prompt=\"What is 17 + 28? Answer with just the number.\", temperature=0.2, max_tokens=128):\n",
    "    demo_prompt = prompt\n",
    "    result = call_model_chat_completions(demo_prompt, temperature=temperature, max_tokens=max_tokens)\n",
    "    print(\"OK:\", result[\"ok\"], \"HTTP:\", result[\"status\"])\n",
    "    print(\"MODEL SAYS:\", (result[\"text\"] or \"\").strip())\n",
    "\n",
    "    # Optional: Inspect rate-limit headers if your provider exposes them\n",
    "    for k in [\"x-ratelimit-remaining-requests\", \"x-ratelimit-limit-requests\", \"x-request-id\"]:\n",
    "        if k in result[\"headers\"]:\n",
    "            print(f\"{k}: {result['headers'][k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a3b0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define three tests: input + expected\n",
    "my_tests = [\n",
    "    {\n",
    "        \"id\": \"math_inequality\",\n",
    "        \"type\": \"numeric\",  # grader will prefer numeric extraction\n",
    "        \"prompt\": \"Solve for the smallest integer n such that 3n + 5 > 26. Answer with just the integer.\",\n",
    "        \"expected\": \"8\",    # Because 3n > 21 => n > 7, smallest integer is 8\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"commonsense_ice\",\n",
    "        \"type\": \"text\",\n",
    "        \"prompt\": (\n",
    "            \"You place an ice cube in a glass of water and mark the water level. \"\n",
    "            \"After the ice melts, does the water level rise, fall, or stay the same? \"\n",
    "            \"Answer with exactly one of: 'rise', 'fall', 'stay the same'.\"\n",
    "        ),\n",
    "        \"expected\": \"stay the same\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"logic_race\",\n",
    "        \"type\": \"text\",\n",
    "        \"prompt\": (\n",
    "            \"In a race, you pass the person in second place. What position are you now in? \"\n",
    "            \"Answer with a single word like 'first', 'second', 'third'.\"\n",
    "        ),\n",
    "        \"expected\": \"second\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9af2b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'common_sense': 400, 'math': 300, 'coding': 100, 'future_prediction': 100, 'planning': 100})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "POSSIBLE_TYPES = ['math', 'common_sense', 'planning', 'coding', 'future_prediction']\n",
    "\n",
    "all_tests = json.load(open(\"parsed_dev_data.json\", \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "type_counts = Counter(t['domain'] for t in all_tests)\n",
    "print(type_counts)\n",
    "\n",
    "formatted_tests = []\n",
    "for i, t in enumerate(all_tests, start=1):\n",
    "    \n",
    "    formatted_tests.append({\n",
    "        \"id\": t['id'], # domain_domainIndex_domainTestIndex_testIndex\n",
    "        \"type\": t['domain'],\n",
    "        \"prompt\": t['input'],\n",
    "        \"expected\": t['output'],\n",
    "        \"char_count\": t['input_char_count'],\n",
    "        \"exp_word_count\": t['exp_word_count']\n",
    "    })\n",
    "    \n",
    "all_tests = formatted_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe04856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" def get_test_type(test_type, start=0, end=None, lower=0, upper=float('inf')):\\n    tests = [t for t in all_tests if t['type'] in test_type and lower <= t['char_count'] <= upper]\\n    return tests[start:end]\\n\\ndef get_random_tests(n=5, lower=0, upper=float('inf'), test_type=POSSIBLE_TYPES):\\n    filtered_tests = get_test_type(test_type=test_type, lower=lower, upper=upper) #[t for t in all_tests if lower <= t['char_count'] <= upper]\\n    sample_size = min(n, len(filtered_tests)) #prevent error\\n    return random.sample(filtered_tests, sample_size) \""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_test(test):\n",
    "    print(json.dumps(test, indent=2, ensure_ascii=False))\n",
    "\n",
    "#pass test_type as a list of types\n",
    "#generalized get test function\n",
    "def get_tests(n=0, test_type=POSSIBLE_TYPES, start=0, end=None, lower_char=0, upper_char=float('inf'), lower_exp=0, upper_exp=float('inf')):\n",
    "    filtered_tests = [t for t in all_tests if t['type'] in test_type and lower_char <= t['char_count'] <= upper_char and lower_exp <= t['exp_word_count'] <= upper_exp]\n",
    "    print('filtered size:', len(filtered_tests))\n",
    "    sample_size = min(n, len(filtered_tests))\n",
    "    \n",
    "    if n == 0:\n",
    "        return filtered_tests[start:end]\n",
    "    elif n == -1:\n",
    "        filtered_type_counts = Counter(t['type'] for t in filtered_tests)\n",
    "        each_test = []\n",
    "        count = 0\n",
    "        \n",
    "        for val in filtered_type_counts.values():\n",
    "            rand = random.randint(count, count + val)\n",
    "            count = count + val\n",
    "            each_test.append(filtered_tests[rand])\n",
    "            \n",
    "        print(\"sampled size:\", len(each_test))    \n",
    "        return each_test\n",
    "    else:\n",
    "        return random.sample(filtered_tests, sample_size)\n",
    "    \n",
    "\"\"\" def get_test_type(test_type, start=0, end=None, lower=0, upper=float('inf')):\n",
    "    tests = [t for t in all_tests if t['type'] in test_type and lower <= t['char_count'] <= upper]\n",
    "    return tests[start:end]\n",
    "\n",
    "def get_random_tests(n=5, lower=0, upper=float('inf'), test_type=POSSIBLE_TYPES):\n",
    "    filtered_tests = get_test_type(test_type=test_type, lower=lower, upper=upper) #[t for t in all_tests if lower <= t['char_count'] <= upper]\n",
    "    sample_size = min(n, len(filtered_tests)) #prevent error\n",
    "    return random.sample(filtered_tests, sample_size) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3f75a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered size: 440\n",
      "3\n",
      "[{'char_count': 274,\n",
      "  'exp_word_count': 59,\n",
      "  'expected': '\\n'\n",
      "              '    exit_codes = []\\n'\n",
      "              '\\n'\n",
      "              '    def execute_file(file):\\n'\n",
      "              '        file_path = file\\n'\n",
      "              '        process = subprocess.Popen(file_path)\\n'\n",
      "              '        time.sleep(1)  # wait for the process to start\\n'\n",
      "              '        exit_codes.append(process.poll())  # store the exit '\n",
      "              'code\\n'\n",
      "              '\\n'\n",
      "              '    # Start a thread for each file\\n'\n",
      "              '    threads = [threading.Thread(target=execute_file, '\n",
      "              'args=(file,)) for file in file_list]\\n'\n",
      "              '    for thread in threads:\\n'\n",
      "              '        thread.start()\\n'\n",
      "              '\\n'\n",
      "              '    # Wait for all threads to finish\\n'\n",
      "              '    for thread in threads:\\n'\n",
      "              '        thread.join()\\n'\n",
      "              '\\n'\n",
      "              '    return exit_codes',\n",
      "  'id': 'coding_0_99_99',\n",
      "  'prompt': 'Run files from list of files as subprocesses at the same time.\\n'\n",
      "            'The function should output with:\\n'\n",
      "            '    list: The exit codes of the subprocesses.\\n'\n",
      "            'You should write self-contained code starting with:\\n'\n",
      "            '```\\n'\n",
      "            'import subprocess\\n'\n",
      "            'import time\\n'\n",
      "            'import threading\\n'\n",
      "            'def task_func(file_list):\\n'\n",
      "            '```',\n",
      "  'type': 'coding'},\n",
      " {'char_count': 65,\n",
      "  'exp_word_count': 1,\n",
      "  'expected': 'Canada',\n",
      "  'id': 'common_sense_1_294_394',\n",
      "  'prompt': 'Iqaluit Airport and Canadian North are based out of what country?',\n",
      "  'type': 'common_sense'},\n",
      " {'char_count': 161,\n",
      "  'exp_word_count': 4,\n",
      "  'expected': '\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)',\n",
      "  'id': 'math_3_210_810',\n",
      "  'prompt': 'Convert the point $(0,3)$ in rectangular coordinates to polar '\n",
      "            'coordinates.  Enter your answer in the form $(r,\\\\theta),$ where '\n",
      "            '$r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$',\n",
      "  'type': 'math'}]\n"
     ]
    }
   ],
   "source": [
    "tests = get_tests(n=-1, upper_char=300) #get_test_type('math', end=10, lower=0, upper=500)\n",
    "pprint(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b72b0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple hello world call to kick off the commits\n",
    "#direct_call(prompt=\"how do I find the derivative of y=x^2 using python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54e39fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    messages = [\"<Start of message history>\"]\n",
    "    count = 0\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "        response = call_model_chat_completions(prompt=f\"Old messages{messages}, CURRENT USER INPUT:{user_input} <--- ANSWER THIS QUESTION\", temperature=0.7)\n",
    "        count += 1\n",
    "        messages.append(f\"MESSAGE_{count}_[previous user input: {user_input}, previous system response: {response['text']}]\")\n",
    "        if response[\"ok\"]:\n",
    "            print(\"Model:\", response[\"text\"].strip())\n",
    "        else:\n",
    "            print(\"Error:\", response[\"error\"])\n",
    "        print(messages)\n",
    "#interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d8dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def execute_tests():\\n    rows = []\\n    for t in tests:\\n        r = call_model_chat_completions(\\n            prompt,\\n            system=system,\\n            model=model,\\n            temperature=0.3,\\n            max_tokens=128\\n        ) '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def execute_tests():\n",
    "    rows = []\n",
    "    for t in tests:\n",
    "        r = call_model_chat_completions(\n",
    "            prompt,\n",
    "            system=system,\n",
    "            model=model,\n",
    "            temperature=0.3,\n",
    "            max_tokens=128\n",
    "        ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e38f632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate(question, prediction, expected_answer, model=MODEL):\n",
    "    \"\"\"\n",
    "    Use the model itself as a strict grader.\n",
    "    Returns True if the model says the prediction matches the expected answer; else False.\n",
    "    Falls back to a simple normalized string compare if the model's reply is malformed.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    system = \"You are a strict grader. Reply with exactly True or False. No punctuation. No explanation.\"\n",
    "    prompt = f\"\"\"You are grading a question-answer pair.\n",
    "\n",
    "Return exactly True if the PREDICTION would be accepted as correct for the EXPECTED_ANSWER.\n",
    "Otherwise, return False.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "PREDICTION:\n",
    "{prediction}\n",
    "\n",
    "EXPECTED_ANSWER:\n",
    "{expected_answer}\n",
    "\n",
    "Answer with exactly: True or False\n",
    "\"\"\"\n",
    "\n",
    "    r = call_model_chat_completions(\n",
    "        prompt,\n",
    "        system=system,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    reply = (r.get(\"text\") or \"\").strip().lower()\n",
    "    if reply.startswith(\"true\"):\n",
    "        return True\n",
    "    if reply.startswith(\"false\"):\n",
    "        return False\n",
    "\n",
    "    # No Fallback yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate2(question, model_output, prediction, expected_answer, model=MODEL):\n",
    "    \"\"\"\n",
    "    Use the model itself as a strict grader.\n",
    "    Returns True if the model says the prediction matches the expected answer; else False.\n",
    "    Falls back to a simple normalized string compare if the model's reply is malformed.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    system = \"You are a strict grader. Reply with exactly True or False. No punctuation. No explanation.\"\n",
    "    prompt = f\"\"\"You are grading an automated evaluation algorithm that returns true or false depending on the model's output.\n",
    "\n",
    "Return exactly True if the automated grading algorithm's PREDICTION on the correctness of MODEL_OUTPUT would be accepted as correct for the EXPECTED_ANSWER.\n",
    "Otherwise, return False.\n",
    "\n",
    "QUESTION (The user prompt):\n",
    "{question}\n",
    "\n",
    "MODEL_OUTPUT (Output returned from model for user prompt)\n",
    "{model_output}\n",
    "\n",
    "PREDICTION (autograder correctness output):\n",
    "{prediction}\n",
    "\n",
    "EXPECTED_ANSWER (does MODEL_OUTPUT actually contain the correct answer):\n",
    "{expected_answer}\n",
    "\n",
    "Answer with exactly: True or False, depending if the autograder returned the correct grade.\n",
    "\"\"\"\n",
    "\n",
    "    r = call_model_chat_completions(\n",
    "        prompt,\n",
    "        system=system,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    reply = (r.get(\"text\") or \"\").strip().lower()\n",
    "    if reply.startswith(\"true\"):\n",
    "        return True\n",
    "    if reply.startswith(\"false\"):\n",
    "        return False\n",
    "\n",
    "    # No Fallback yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e2ca1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_map = {'yes':'true', 'no':'false'}\n",
    "def map_tf(output):\n",
    "    out = output.lower().strip('.')\n",
    "    return tf_map.get(out) if out in tf_map else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4c59a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def basic_match_check(test, output):\n",
    "    exp = test[\"expected\"]\n",
    "    \n",
    "    output = map_tf(output)\n",
    "    \n",
    "    matches = re.findall(re.escape(str(exp)), output, re.IGNORECASE)\n",
    "    \n",
    "    num_matches = len(matches)\n",
    "    if num_matches > 0:\n",
    "        #print('MATCH(ES) FOUND:', matches)\n",
    "        return True\n",
    "    \n",
    "    #print('NO MATCH FOUND')\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "baa83c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperator(text, tokens_used=None, max_tokens=400):\n",
    "    if tokens_used is not None:\n",
    "        print(f'{text} (TOKENS USED: {tokens_used}/{max_tokens})')\n",
    "        if int(tokens_used) > max_tokens: print('MAXED TOKENS REACHED - OUTPUT TRUNCATED')\n",
    "    else:\n",
    "        print(text)\n",
    "    print('-'*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7cdafb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate_tests(tests, model=MODEL, grader_model=None, sleep_sec=0.2, verbose=True):\n",
    "    \"\"\"\n",
    "    Run the tests by querying the model for each prompt, then use LLM-as-a-judge\n",
    "    (self_evaluate) to determine correctness.\n",
    "\n",
    "    Args:\n",
    "        tests: list of dicts with keys: id, prompt, expected (and optionally type)\n",
    "        model: model used to generate predictions\n",
    "        grader_model: model used to judge correctness (defaults to `model` if None)\n",
    "        sleep_sec: small delay between calls to be polite to the API\n",
    "        verbose: if True, print a summary line per test\n",
    "\n",
    "    Returns:\n",
    "        rows: list of dicts with fields:\n",
    "              id, expected, got, correct, status, error\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    judge_model = grader_model or model\n",
    "    MAX_TOKENS = 400\n",
    "\n",
    "    count = 0\n",
    "    for t in tests:\n",
    "        count += 1\n",
    "        # 1) Get model prediction\n",
    "        #print('prompt:', t['prompt'])\n",
    "        print('='*64)\n",
    "        seperator('TEST_CASE')\n",
    "        print_test(t)\n",
    "        r = call_model_chat_completions(\n",
    "            f\"{t['prompt']}\",\n",
    "            system=\"Give a short answer to each prompt, don't explain.\",\n",
    "            model=model,\n",
    "            temperature=0.3,\n",
    "            max_tokens=MAX_TOKENS\n",
    "        )\n",
    "        got = (r.get(\"text\") or \"\").strip()\n",
    "        tokens_used = (r.get(\"tokens_used\") or \"\")\n",
    "        \n",
    "\n",
    "        got = map_tf(got)\n",
    "        \n",
    "        seperator('\\nMODEL_OUTPUT', tokens_used, MAX_TOKENS)\n",
    "        display(Markdown(f\"\\n{got}\"))\n",
    "        #print('raw: ', got)\n",
    "        \n",
    "        match_check = basic_match_check(t, got)\n",
    "        match_check = bool(match_check)\n",
    "        \n",
    "        # 2) LLM-as-a-judge: strict True/False\n",
    "        is_correct = self_evaluate(\n",
    "            question=t[\"prompt\"],\n",
    "            prediction=got,\n",
    "            expected_answer=t[\"expected\"],\n",
    "            model=judge_model,\n",
    "        )\n",
    "        is_correct = bool(is_correct)\n",
    "        \n",
    "        seperator('\\nEVALUATION')\n",
    "        print('match check:', match_check)\n",
    "        print('self_eval:', is_correct)\n",
    "        correctness = is_correct and match_check\n",
    "        agreement = is_correct == match_check\n",
    "        print('‚úÖ CORRECT') if correctness else print('‚ùå INCORRECT')\n",
    "        print('üÜó AGREED') if agreement else print('üÜò DISAGREED')\n",
    "\n",
    "\n",
    "        if sleep_sec:\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    return correctness\n",
    "\n",
    "# Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3bb4c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7eacd731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered size: 1000\n",
      "================================================================\n",
      "TEST_CASE\n",
      "--------------------------------\n",
      "{\n",
      "  \"id\": \"common_sense_1_204_304\",\n",
      "  \"type\": \"common_sense\",\n",
      "  \"prompt\": \"What American stage, film, and television actor  who also appeared in a large number of musicals, played Samson in the 1949 film \\\"Samson and Delilah\\\".\",\n",
      "  \"expected\": \"Victor John Mature\",\n",
      "  \"char_count\": 150,\n",
      "  \"exp_word_count\": 3\n",
      "}\n",
      "\n",
      "MODEL_OUTPUT (TOKENS USED: 3/400)\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Gary Cooper"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION\n",
      "--------------------------------\n",
      "match check: False\n",
      "self_eval: False\n",
      "‚ùå INCORRECT\n",
      "üÜó AGREED\n",
      "================================================================\n",
      "TEST_CASE\n",
      "--------------------------------\n",
      "{\n",
      "  \"id\": \"common_sense_1_284_384\",\n",
      "  \"type\": \"common_sense\",\n",
      "  \"prompt\": \"Is capturing giant squid in natural habitat impossible with no gear?\",\n",
      "  \"expected\": true,\n",
      "  \"char_count\": 68,\n",
      "  \"exp_word_count\": 1\n",
      "}\n",
      "\n",
      "MODEL_OUTPUT (TOKENS USED: 3/400)\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "true"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION\n",
      "--------------------------------\n",
      "match check: True\n",
      "self_eval: True\n",
      "‚úÖ CORRECT\n",
      "üÜó AGREED\n",
      "================================================================\n",
      "TEST_CASE\n",
      "--------------------------------\n",
      "{\n",
      "  \"id\": \"coding_0_57_57\",\n",
      "  \"type\": \"coding\",\n",
      "  \"prompt\": \"Counts the number of words, characters, and unique characters in a given text.\\nNote that: This function considers whitespace-separated substrings as words. When counting characters, this function excludes whitespace and special characters (i.e. string.punctuation).\\nThe function should output with:\\n    tuple: A tuple containing three integers: the number of words,\\n    the number of characters,\\n    the number of unique characters.\\nYou should write self-contained code starting with:\\n```\\nimport string\\nimport re\\ndef task_func(text: str) -> tuple:\\n```\",\n",
      "  \"expected\": \"    words = text.split()\\n    chars = re.sub(\\\"\\\\s\\\", \\\"\\\", re.sub(f\\\"[{string.punctuation}]\\\", \\\"\\\", text))\\n\\n    return len(words), len(chars), len(set(chars))\",\n",
      "  \"char_count\": 551,\n",
      "  \"exp_word_count\": 14\n",
      "}\n",
      "\n",
      "MODEL_OUTPUT (TOKENS USED: 78/400)\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "```python\n",
       "import string\n",
       "import re\n",
       "\n",
       "def task_func(text: str) -> tuple:\n",
       "    words = len(text.split())\n",
       "    chars = len(re.sub(r'[^a-zA-Z0-9]', '', text))\n",
       "    unique_chars = len(set(re.sub(r'[^a-zA-Z0-9]', '', text)))\n",
       "    return (words, chars, unique_chars)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION\n",
      "--------------------------------\n",
      "match check: False\n",
      "self_eval: False\n",
      "‚ùå INCORRECT\n",
      "üÜó AGREED\n",
      "================================================================\n",
      "TEST_CASE\n",
      "--------------------------------\n",
      "{\n",
      "  \"id\": \"planning_4_36_936\",\n",
      "  \"type\": \"planning\",\n",
      "  \"prompt\": \"I have to plan the logistics of transporting crates between a number of depots and distributors via trucks that are loaded by hoists. Depots and distributors are directly connected by roads (trucks can drive between any two depots or distributors).\\n\\nA depot is a type of place.\\nA distributor is a type of place.\\nA pallet is a type of surface.\\nA crate is a type of surface.\\n\\nHere are the actions that can be performed:\\n\\nDrive a truck from one place to another place.\\nUse a hoist to lift a crate from a surface at a place.\\nUse a hoist to drop a crate to a surface at a place.\\nUse a hoist to load a crate into a truck at a place.\\nUse a hoist to unload a crate from a truck at a place.\\n\\nThe following are the restrictions on the actions:\\nA truck can be driven from one place to another place only if the truck is at the origin place.\\nOnce a truck has been driven from one place to another, it is not at the origin place and is at the destination place.\\nA crate can be lifted by a hoist only if the hoist is at the same place as the crate, the hoist is available, and the crate is clear.\\nOnce a crate has been lifted by a hoist from a surface at a place, the crate is not at the place, the hoist is lifting the crate, the hoist is not available, the surface is clear, and the crate is not on the surface.\\nA crate can be dropped by a hoist to a surface only if the hoist and surface are both at the place, the surface is clear, and the hoist is lifting the crate.\\nOnce a crate has been dropped by a hoist to a surface at a place, the hoist is available, the hoist is not lifting the crate, the crate is at the place, the surface is not clear, the crate is clear, and the crate is on the surface.\\nA crate can be loaded by a hoist onto a truck at a place only if the hoist is at the same place, the truck is at the same place, and the hoist is lifting the crate.\\nOnce a crate has been loaded by a hoist onto a truck at a place, \\nA crate can be unloaded by a hoist from a truck at a place only if the hoist is at the same place as the truck, the hoist is available, and the crate is in the truck.\\nOnce a crate has been unloaded by a hoist from a truck at a place, the crate is not in the truck, the hoist is not available, and the hoist is lifting the crate.\\n\\n[STATEMENT]\\nAs initial conditions I have that, crate0 is at depot0, crate1 is at depot0, crate2 is at distributor0, hoist0 is at depot0, hoist1 is at depot1, hoist2 is at depot2, hoist3 is at distributor0, pallet0 is at depot0, pallet1 is at depot1, pallet2 is at depot2, pallet3 is at distributor0, truck0 is at depot2, truck1 is at depot0, truck2 is at depot0, hoist0 is available, hoist1 is available, hoist2 is available, hoist3 is available, crate1 is clear, crate2 is clear, pallet1 is clear, pallet2 is clear, crate0 is on pallet0, crate1 is on crate0 and crate2 is on pallet3.\\nMy goal is to have that crate0 is on pallet2 and crate1 is on crate0.\\n\\nMy plan is as follows:\\n\\n[PLAN]\\nUse hoist0 to lift crate1 from crate0 at depot0\\nUse hoist0 to load crate1 into truck2 at depot0\\nUse hoist0 to lift crate0 from pallet0 at depot0\\nUse hoist0 to load crate0 into truck2 at depot0\\ndrive truck2 from depot0 to depot2\\nUse hoist2 to unload crate0 from truck2 at depot2\\nUse hoist2 to drop crate0 to pallet2 at depot2\\nUse hoist2 to unload crate1 from truck2 at depot2\\nUse hoist2 to drop crate1 to crate0 at depot2\\n[PLAN END]\\n\\n[STATEMENT]\\nAs initial conditions I have that, crate0 is at depot1, crate1 is at depot0, crate2 is at distributor0, hoist0 is at depot0, hoist1 is at depot1, hoist2 is at depot2, hoist3 is at distributor0, pallet0 is at depot0, pallet1 is at depot1, pallet2 is at depot2, pallet3 is at distributor0, truck0 is at distributor0, truck1 is at depot0, truck2 is at depot1, hoist0 is available, hoist1 is available, hoist2 is available, hoist3 is available, crate0 is clear, crate1 is clear, crate2 is clear, pallet2 is clear, crate0 is on pallet1, crate1 is on pallet0 and crate2 is on pallet3.\\nMy goal is to have that crate0 is on pallet3 and crate2 is on pallet0.\\n\\nMy plan is as follows:\\n\\n[PLAN]\",\n",
      "  \"expected\": \"(lift hoist1 crate0 pallet1 depot1)\\n(load hoist1 crate0 truck2 depot1)\\n(drive truck2 depot1 distributor0)\\n(lift hoist3 crate2 pallet3 distributor0)\\n(load hoist3 crate2 truck2 distributor0)\\n(unload hoist3 crate0 truck2 distributor0)\\n(drive truck2 distributor0 depot0)\\n(drop hoist3 crate0 pallet3 distributor0)\\n(lift hoist0 crate1 pallet0 depot0)\\n(load hoist0 crate1 truck2 depot0)\\n(unload hoist0 crate2 truck2 depot0)\\n(drop hoist0 crate2 pallet0 depot0)\\n\",\n",
      "  \"char_count\": 4064,\n",
      "  \"exp_word_count\": 58\n",
      "}\n",
      "\n",
      "MODEL_OUTPUT (TOKENS USED: 140/400)\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Use hoist1 to lift crate0 from pallet1 at depot1  \n",
       "Use hoist1 to load crate0 into truck2 at depot1  \n",
       "Drive truck2 from depot1 to distributor0  \n",
       "Use hoist3 to unload crate0 from truck2 at distributor0  \n",
       "Use hoist3 to drop crate0 to pallet3 at distributor0  \n",
       "Use hoist3 to lift crate2 from pallet3 at distributor0  \n",
       "Use hoist3 to load crate2 into truck0 at distributor0  \n",
       "Drive truck0 from distributor0 to depot0  \n",
       "Use hoist0 to unload crate2 from truck0 at depot0  \n",
       "Use hoist0 to drop crate2 to pallet0 at depot0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION\n",
      "--------------------------------\n",
      "match check: False\n",
      "self_eval: True\n",
      "‚ùå INCORRECT\n",
      "üÜò DISAGREED\n",
      "================================================================\n",
      "TEST_CASE\n",
      "--------------------------------\n",
      "{\n",
      "  \"id\": \"planning_4_81_981\",\n",
      "  \"type\": \"planning\",\n",
      "  \"prompt\": \"I am playing with a set of objects. Here are the actions I can do\\n\\n   Attack object\\n   Feast object from another object\\n   Succumb object\\n   Overcome object from another object\\n\\nI have the following restrictions on my actions:\\n    To perform Attack action, the following facts need to be true: Province object, Planet object, Harmony.\\n    Once Attack action is performed the following facts will be true: Pain object.\\n    Once Attack action is performed the following facts will be false: Province object, Planet object, Harmony.\\n    To perform Succumb action, the following facts need to be true: Pain object.\\n    Once Succumb action is performed the following facts will be true: Province object, Planet object, Harmony.    \\n    Once Succumb action is performed the following facts will be false: Pain object.\\n    To perform Overcome action, the following needs to be true: Province other object, Pain object.\\n    Once Overcome action is performed the following will be true: Harmony, Province object, Object Craves other object.\\n    Once Overcome action is performed the following will be false: Province other object, Pain object.\\n    To perform Feast action, the following needs to be true: Object Craves other object, Province object, Harmony.\\n    Once Feast action is performed the following will be true: Pain object, Province other object.\\n    Once Feast action is performed the following will be false:, Object Craves other object, Province object, Harmony.\\n\\n[STATEMENT]\\nAs initial conditions I have that, object a craves object d, object b craves object c, object c craves object a, harmony, planet object d and province object b.\\nMy goal is to have that object a craves object b and object c craves object a.\\n\\nMy plan is as follows:\\n\\n[PLAN]\\nfeast object b from object c\\nsuccumb object b\\nfeast object c from object a\\nsuccumb object c\\nfeast object a from object d\\novercome object a from object b\\nattack object c\\novercome object c from object a\\n[PLAN END]\\n\\n[STATEMENT]\\nAs initial conditions I have that, object a craves object b, object c craves object d, object d craves object a, harmony, planet object b and province object c.\\nMy goal is to have that object b craves object a and object c craves object d.\\n\\nMy plan is as follows:\\n\\n[PLAN]\",\n",
      "  \"expected\": \"(feast c d)\\n(succumb c)\\n(feast d a)\\n(succumb d)\\n(attack c)\\n(overcome c d)\\n(feast a b)\\n(succumb a)\\n(attack b)\\n(overcome b a)\\n\",\n",
      "  \"char_count\": 2249,\n",
      "  \"exp_word_count\": 25\n",
      "}\n",
      "\n",
      "MODEL_OUTPUT (TOKENS USED: 66/400)\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "feast object a from object d  \n",
       "overcome object a from object b  \n",
       "attack object d  \n",
       "succumb object d  \n",
       "feast object d from object c  \n",
       "overcome object d from object c  \n",
       "attack object c  \n",
       "succumb object c  \n",
       "feast object c from object a  \n",
       "overcome object c from object a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION\n",
      "--------------------------------\n",
      "match check: False\n",
      "self_eval: False\n",
      "‚ùå INCORRECT\n",
      "üÜó AGREED\n"
     ]
    }
   ],
   "source": [
    "test_prompts = get_tests(n=5) #get_test_type([\"math\"],end=10, upper=300) get_random_tests(n=3, upper=300)\n",
    "results_llm_judge = self_evaluate_tests(test_prompts, verbose=True, model=MODEL, grader_model=MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
